{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Неделя 2. Четверг\n",
    "\n",
    "## Линейная регрессия"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Ваша задача сегодня для лучшего понимания алгоритмов машинного обучения, реализовать свой класс Линейной регрессии на Python и `numpy` в частности.  \n",
    "\n",
    "* на _train_ выборке алгоритму необходиму оубчиться, на _test_ выборке проверить свой результат. Метрика для проверки результата для линейной регрессии - _MSE_, метрики реализовать внутри класса.\n",
    "\n",
    "* В качестве функции потерь, необходимо выбрать _MSE_ - для линейной регрессии. \n",
    "\n",
    "* Также необходиму пользователю Вашей модели предоставить возможность указать регуляризирующие коэффициенты и вид регуляризации('Ridge', 'Lasso', 'ElasticNet').  \n",
    "\n",
    "* При инициализации класса пользователь указывает вид регуляризации, и коэффициенты регуляризации. Если вид не указан регуляризация отсутствует  \n",
    "\n",
    "\n",
    "* После вы можете сравнить свой результат со стандартной Линейной регрессией, реализованной в _sklearn_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Подгрузите необходимые библиотеки\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('aux/train_flats.csv')\n",
    "test = pd.read_csv('aux/test_flats.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __m2__ - площадь объекта (фича)\n",
    "* __dist__ - удаленность объекта от центра города(фича)\n",
    "* __price__ - цена (таргет)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. Отнормируйте свои данные, используя [StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html). Для линейных алгоритмов это очень важно  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSELoss = $\\dfrac{1}{N} \\sum_{i=1}^{N}(y_{act} - y_{pred})^2 = \\dfrac{1}{N} \\sum_{i=1}^{N}(y_{act} - (\\omega_0 + x_{i1} \\cdot \\omega_1 + x_{i2} \\cdot \\omega_2 + ... + x_{in} \\cdot \\omega_n))^2$ "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*  Возьмем функцию потерь на одном объекте"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$L = (y_{act} - y_{pred})^2$  \n",
    "  \n",
    "$y_{act} - $ реальное значение, которое принимает наша величина\n",
    "\n",
    "$y_{pred} - $ значение, которое будет предсказывать наша модель\n",
    "\n",
    "\n",
    "Наше желание, чтобы модель, на каждом элементе выборки предсказывала значение как можно ближе к реальному\n",
    "\n",
    "* Как это сделать?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы знаем, что в случае линейной регрессии наше предсказание строится как  \n",
    "\n",
    "$y_{pred} = (\\omega_0 + x_{1} \\cdot \\omega_1 + x_{2} \\cdot \\omega_2 + ... + x_{n} \\cdot \\omega_n)$  \n",
    "\n",
    "$w_0, w_1, w_2, ..., w_n$ - Параметры, которые мы могли бы настроить!  \n",
    "\n",
    "Итоговая функция потерь на одном объекте:\n",
    "\n",
    "$L(\\vec{w}) = (y_{act} - (\\omega_0 + x_{i1} \\cdot \\omega_1 + x_{i2} \\cdot \\omega_2 + ... + x_{in} \\cdot \\omega_n))^2$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$L(\\vec{w})$ - сложная функция, которая состоит из следующих функциональных преобразований:  \n",
    "* возведения в квадрат\n",
    "* домножения наших $\\omega$ на константу - входные данные $x_1, x_2, ..., x_n$. Да да, именно они являются константами\n",
    "\n",
    "(_Смотреть выше расписанную формулу_)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Посчитать для $L(\\vec{w}) = (y_{act} - (\\omega_0 + x_{i1} \\cdot \\omega_1 + x_{i2} \\cdot \\omega_2 + ... + x_{in} \\cdot \\omega_n))^2$ сложную частную производную по $w_1$.\n",
    "\n",
    "Как будет отличаться частная производная для $w_2, w_3, ..., w_n$?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Посчитать частную производную для $w_0$. (Свободного члена)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Математически градиент готов, останется обернуть его в алгоритм градиентного спуска и на реальных данных, где у нас ни один объект, а много сразу.\n",
    "Единственной разницей того, что объектов много сразу, мы будем минимизировать функцию потерь в среднем на всех элементах.\n",
    "\n",
    "Формула для одного объекта была бы такой:\n",
    "    \n",
    "$\\vec{w_{new}} = \\vec{w_{old}} - lr * grad L(\\vec{w_{old}})$  \n",
    "\n",
    "Для всех объектов: \n",
    "\n",
    "1. Высчитывается градиент на каждом из ваших объектов(везде получаются разные $grad L(\\vec{w_{old}})$ - так как у каждого объекта свои $y, x_1, x_2, ...$).\n",
    "2. Берется средний $\\vec{\\omega_{old}}$ - по нему вычисляется новый $\\vec{w_{new}}$ у модели\n",
    "\n",
    "Итого:\n",
    "\n",
    "$\\vec{w_{new}} = \\vec{w_{old}} - lr * mean(grad L(\\vec{w_{old}}))$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Создать класс LinReg. При инициализации дать возможность указать learning_rate, кол-во входных фичей(n). Записать эту информацию в атрибуты класса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class LinReg:\n",
    "#     def __init__(self, learning_rate, n_inputs):\n",
    "#         self.learning_rate = ...\n",
    "#         self.n_inputs = ..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Создать случайную инициализцию необходимых $\\omega$ (Их будет n+1). Инициализируйте их равномерным распределением w1, w2, ..., wn = положите в атрибут - coef_, w0(свободный член) положите в атрибут intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class LinReg:\n",
    "#     def __init__(self, learning_rate, n_inputs):\n",
    "#         self.learning_rate = ...\n",
    "#         self.n_inputs = ...\n",
    "#         self.coef_ = ...\n",
    "#         self.intercept_ = ..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Опишите метод fit, который будет принимать на вход X, y (X - данные x1, x2, ..., xn, y - это $y_{act})$ и высчитывать с помощью градиентного спуска самые оптимальные параметры w0, w1, w2, ..., wn. Которые будут хранится в атрибутах coef_ и intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class LinReg:\n",
    "#     def __init__(self, learning_rate, n_inputs):\n",
    "#         self.learning_rate = ...\n",
    "#         self.n_inputs = ...\n",
    "#         self.coef_ = ...\n",
    "#         self.intercept_ = ...\n",
    "        \n",
    "#     def fit(self, X, y):\n",
    "#         pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Опишите метод predict, который будет предсказывать для новых точек в дальнейшем их y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class LinReg:\n",
    "#     def __init__(self, learning_rate, n_inputs):\n",
    "#         self.learning_rate = ...\n",
    "#         self.n_inputs = ...\n",
    "#         self.coef_ = ...\n",
    "#         self.intercept_ = ...\n",
    "        \n",
    "#     def fit(self, X, y):\n",
    "#         pass\n",
    "\n",
    "#     def predict(self, X):\n",
    "#         pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Сравните результат с линейной регрессией в sklearn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# lr = LinearRegression()\n",
    "# lr.fit(X, y)\n",
    "# lr.coef_, lr.intercept_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Напшите метод _score_. Который принимает данные _X_ и _y_  и высчитывает функционал качества, можно оставить тот же [MSE](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html#sklearn.metrics.mean_squared_error). Он нам понадобится для оценки качества работы алгоритмы на тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class LinReg:\n",
    "#     def __init__(self, learning_rate, n_inputs):\n",
    "#         self.learning_rate = ...\n",
    "#         self.n_inputs = ...\n",
    "#         self.coef_ = ...\n",
    "#         self.intercept_ = ...\n",
    "        \n",
    "#     def fit(self, X, y):\n",
    "#         pass\n",
    "\n",
    "#     def predict(self, X):\n",
    "#         pass\n",
    "\n",
    "#     def score(self, X, y):\n",
    "#         pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Посчитайте ваш _score_ и линейной регрессии из sklearn для тестового набора данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Нарисуйте 3D график, на котором будет следующее:\n",
    "\n",
    "* ось X и Y - [['m2', 'dist']]\n",
    "* ось Z -  price\n",
    "* через scatter все элементы выборки. Красными точками train, Синими test\n",
    "* Линейную плоскость предсказания"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10*. Добавьте возможность пользователю добавлять реугляризацию модели. Это не привносит больших изменений. Немного пмоеняется функция потерь и как следствие градиент"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class LinReg:\n",
    "#     def __init__(self, learning_rate, n_inputs, reg_type='Ridge', alpha=0.2):\n",
    "#         self.learning_rate = ...\n",
    "#         self.n_inputs = ...\n",
    "#         self.coef_ = ...\n",
    "#         self.intercept_ = ...\n",
    "        \n",
    "#     def fit(self, X, y):\n",
    "#         pass\n",
    "\n",
    "#     def predict(self, X):\n",
    "#         pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
